{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORATION 14. 인물사진을 만들어 보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 1080, 3)\n"
     ]
    }
   ],
   "source": [
    "img_path = os.getenv('HOME')+'/aiffel/human_segmentation/images/my_image.png'\n",
    "img_orig = cv2.imread(img_path) \n",
    "print (img_orig.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(974, 960, 3)\n"
     ]
    }
   ],
   "source": [
    "cat_img_path = os.getenv('HOME')+'/aiffel/human_segmentation/images/cat.png'\n",
    "cat_img_orig = cv2.imread(cat_img_path) \n",
    "print (cat_img_orig.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 720, 3)\n"
     ]
    }
   ],
   "source": [
    "bacground_img_path = os.getenv('HOME')+'/aiffel/human_segmentation/images/background.png'\n",
    "bacground_img_orig = cv2.imread(bacground_img_path) \n",
    "print (bacground_img_orig.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1104, 736, 3)\n"
     ]
    }
   ],
   "source": [
    "serengeti_img_path = os.getenv('HOME')+'/aiffel/human_segmentation/images/serengeti.png'\n",
    "serengeti_img_orig = cv2.imread(serengeti_img_path) \n",
    "print (serengeti_img_orig.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = os.getenv('HOME')+'/aiffel/human_segmentation/images/image.png'\n",
    "image_ = cv2.imread(image) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabModel(object):\n",
    "    INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
    "    OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
    "    INPUT_SIZE = 513\n",
    "    FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n",
    "\n",
    "    # __init__()에서 모델 구조를 직접 구현하는 대신, tar file에서 읽어들인 그래프구조 graph_def를 \n",
    "    # tf.compat.v1.import_graph_def를 통해 불러들여 활용하게 됩니다. \n",
    "    def __init__(self, tarball_path):\n",
    "        self.graph = tf.Graph()\n",
    "        graph_def = None\n",
    "        tar_file = tarfile.open(tarball_path)\n",
    "        for tar_info in tar_file.getmembers():\n",
    "            if self.FROZEN_GRAPH_NAME in os.path.basename(tar_info.name):\n",
    "                file_handle = tar_file.extractfile(tar_info)\n",
    "                graph_def = tf.compat.v1.GraphDef.FromString(file_handle.read())\n",
    "                break\n",
    "        tar_file.close()\n",
    "\n",
    "        with self.graph.as_default():\n",
    "    \t    tf.compat.v1.import_graph_def(graph_def, name='')\n",
    "\n",
    "        self.sess = tf.compat.v1.Session(graph=self.graph)\n",
    "\n",
    "    # 이미지를 전처리하여 Tensorflow 입력으로 사용 가능한 shape의 Numpy Array로 변환합니다.\n",
    "    def preprocess(self, img_orig):\n",
    "        height, width = img_orig.shape[:2]\n",
    "        resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n",
    "        target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
    "        resized_image = cv2.resize(img_orig, target_size)\n",
    "        resized_rgb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "        img_input = resized_rgb\n",
    "        return img_input\n",
    "        \n",
    "    def run(self, image):\n",
    "        img_input = self.preprocess(image)\n",
    "\n",
    "        # Tensorflow V1에서는 model(input) 방식이 아니라 sess.run(feed_dict={input...}) 방식을 활용합니다.\n",
    "        batch_seg_map = self.sess.run(\n",
    "            self.OUTPUT_TENSOR_NAME,\n",
    "            feed_dict={self.INPUT_TENSOR_NAME: [img_input]})\n",
    "\n",
    "        seg_map = batch_seg_map[0]\n",
    "        return cv2.cvtColor(img_input, cv2.COLOR_RGB2BGR), seg_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp directory: /home/aiffel0046/aiffel/human_segmentation/models\n",
      "model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# define model and download & load pretrained weight\n",
    "_DOWNLOAD_URL_PREFIX = 'http://download.tensorflow.org/models/'\n",
    "\n",
    "model_dir = os.getenv('HOME')+'/aiffel/human_segmentation/models'\n",
    "tf.io.gfile.makedirs(model_dir)\n",
    "\n",
    "print ('temp directory:', model_dir)\n",
    "\n",
    "download_path = os.path.join(model_dir, 'deeplab_model.tar.gz')\n",
    "if not os.path.exists(download_path):\n",
    "    urllib.request.urlretrieve(_DOWNLOAD_URL_PREFIX + 'deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz',\n",
    "                   download_path)\n",
    "\n",
    "MODEL = DeepLabModel(download_path)\n",
    "print('model loaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_NAMES = [\n",
    "    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
    "    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
    "    'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tv'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_resized, seg_map = MODEL.run(img_orig)\n",
    "print (img_orig.shape, img_resized.shape, seg_map.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_show = img_resized.copy()\n",
    "seg_map = np.where(seg_map == 15, 15, 0) # 예측 중 사람만 추출\n",
    "img_mask = seg_map * (255/seg_map.max()) # 255 normalization\n",
    "img_mask = img_mask.astype(np.uint8)\n",
    "color_mask = cv2.applyColorMap(img_mask, cv2.COLORMAP_JET)\n",
    "img_show = cv2.addWeighted(img_show, 0.6, color_mask, 0.35, 0.0)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_show, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask_up = cv2.resize(img_mask, img_orig.shape[:2][::-1], interpolation=cv2.INTER_LINEAR)\n",
    "_, img_mask_up = cv2.threshold(img_mask_up, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "plt.imshow(img_mask_up, cmap=plt.cm.binary_r)\n",
    "ax.set_title('Original Size Mask')\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "plt.imshow(img_mask, cmap=plt.cm.binary_r)\n",
    "ax.set_title('DeepLab Model Mask')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask_color = cv2.cvtColor(img_mask_up, cv2.COLOR_GRAY2BGR)\n",
    "img_bg_mask = cv2.bitwise_not(img_mask_color)\n",
    "img_bg = cv2.bitwise_and(img_orig, img_bg_mask)\n",
    "plt.imshow(img_bg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bg_blur = cv2.blur(img_bg, (13,13))\n",
    "plt.imshow(cv2.cvtColor(img_bg_blur, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_concat = np.where(img_mask_color==255, img_orig, img_bg_blur)\n",
    "plt.imshow(cv2.cvtColor(img_concat, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_resized = cv2.resize(\n",
    "    img_orig, (bacground_img_orig.shape[1], bacground_img_orig.shape[0]))\n",
    "img_mask_resized = cv2.resize(\n",
    "    img_mask_color, (bacground_img_orig.shape[1], bacground_img_orig.shape[0]))\n",
    "\n",
    "img_background_concat = np.where(\n",
    "    img_mask_resized == 255, img_resized, bacground_img_orig)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_background_concat, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_img_resized, cat_seg_map = MODEL.run(cat_img_orig)\n",
    "print (cat_img_orig.shape, cat_img_resized.shape, cat_seg_map.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_img_show = cat_img_resized.copy()\n",
    "cat_seg_map = np.where(cat_seg_map == 8, 8, 0)\n",
    "cat_img_mask = cat_seg_map * (255/cat_seg_map.max()) # 255 normalization\n",
    "cat_img_mask = cat_img_mask.astype(np.uint8)\n",
    "cat_color_mask = cv2.applyColorMap(cat_img_mask, cv2.COLORMAP_JET)\n",
    "cat_img_show = cv2.addWeighted(cat_img_show, 0.6, cat_color_mask, 0.35, 0.0)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(cat_img_show, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_img_mask_up = cv2.resize(cat_img_mask, cat_img_orig.shape[:2][::-1], interpolation=cv2.INTER_LINEAR)\n",
    "_, cat_img_mask_up = cv2.threshold(cat_img_mask_up, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "plt.imshow(cat_img_mask_up, cmap=plt.cm.binary_r)\n",
    "ax.set_title('Original Size Mask')\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "plt.imshow(cat_img_mask, cmap=plt.cm.binary_r)\n",
    "ax.set_title('DeepLab Model Mask')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_img_mask_color = cv2.cvtColor(cat_img_mask_up, cv2.COLOR_GRAY2BGR)\n",
    "cat_img_bg_mask = cv2.bitwise_not(cat_img_mask_color)\n",
    "cat_img_bg = cv2.bitwise_and(cat_img_orig, cat_img_bg_mask)\n",
    "plt.imshow(cat_img_bg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_img_bg_blur = cv2.blur(cat_img_bg, (13,13))\n",
    "plt.imshow(cv2.cvtColor(cat_img_bg_blur, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_img_concat = np.where(cat_img_mask_color==255, cat_img_orig, cat_img_bg_blur)\n",
    "plt.imshow(cv2.cvtColor(cat_img_concat, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_resized = cv2.resize(\n",
    "    cat_img_orig, (serengeti_img_orig.shape[1], cat_img_orig.shape[0]))\n",
    "serengeti_img_resized = cv2.resize(\n",
    "    serengeti_img_orig, (serengeti_img_orig.shape[1], cat_img_orig.shape[0]))\n",
    "cat_img_mask_resized = cv2.resize(\n",
    "    cat_img_mask_color, (serengeti_img_orig.shape[1], cat_img_orig.shape[0]))\n",
    "\n",
    "cat_serengeti_concat = np.where(\n",
    "    cat_img_mask_resized == 255, cat_resized, serengeti_img_resized)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(cat_serengeti_concat, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "ax = plt.subplot(2,3,1)\n",
    "plt.axis('off')\n",
    "img_orig_resized = cv2.resize(img_orig, (400, 400))\n",
    "plt.imshow(cv2.cvtColor(img_orig_resized, cv2.COLOR_BGR2RGB))\n",
    "ax.set_title('Original person')\n",
    "\n",
    "ax = plt.subplot(2,3,2)\n",
    "plt.axis('off')\n",
    "img_concat_resized = cv2.resize(img_concat, (400, 400))\n",
    "plt.imshow(cv2.cvtColor(img_concat_resized, cv2.COLOR_BGR2RGB))\n",
    "ax.set_title('DeepLab person')\n",
    "\n",
    "ax = plt.subplot(2,3,3)\n",
    "plt.axis('off')\n",
    "img_background_concat_resized = cv2.resize(img_background_concat, (400, 400))\n",
    "plt.imshow(cv2.cvtColor(img_background_concat_resized, cv2.COLOR_BGR2RGB))\n",
    "ax.set_title('Background person')\n",
    "\n",
    "ax = plt.subplot(2,3,4)\n",
    "plt.axis('off')\n",
    "cat_img_orig_resized = cv2.resize(cat_img_orig, (400, 400))\n",
    "plt.imshow(cv2.cvtColor(cat_img_orig_resized, cv2.COLOR_BGR2RGB))\n",
    "ax.set_title('Original cat')\n",
    "\n",
    "ax = plt.subplot(2,3,5)\n",
    "plt.axis('off')\n",
    "cat_img_concat_resized = cv2.resize(cat_img_concat, (400, 400))\n",
    "plt.imshow(cv2.cvtColor(cat_img_concat_resized, cv2.COLOR_BGR2RGB))\n",
    "ax.set_title('DeepLab cat')\n",
    "\n",
    "ax = plt.subplot(2,3,6)\n",
    "plt.axis('off')\n",
    "cat_serengeti_concat_resized = cv2.resize(cat_serengeti_concat, (400, 400))\n",
    "plt.imshow(cv2.cvtColor(cat_serengeti_concat_resized, cv2.COLOR_BGR2RGB))\n",
    "ax.set_title('Background cat')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고양이 사진과 제 사진을 이요하여 아웃포커싱 사진들을 만들어봤습니다. 그리고 크로마키 배경도 합성해보았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과물을 보면 object주변에 경계선이 그려지는 것을 볼 수있는데, 굉장히 부자연스러워 보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(image_, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제가 생각해본 해결책은 다음과 같습니다.  \n",
    "\n",
    "1. semantic segmentaion을 적용하여 원하는 물체를 찾아냅니다.\n",
    "2. 찾아낸 부분을 이용하여 마스크1을 만듭니다.\n",
    "3. 마스크1 부분의 pixel을 조금씩 이동시켜서 마스크2, 마스크3을 만들어냅니다.\n",
    "4. 3개의 마스크를 이용하여 각각 원본과 배경을 concat합니다.\n",
    "5. concat으로 만들어지 3개의 영상을 struct2depth 모델을 이용하여 Depth를 계산하고, 원하는 이미지를 얻어냅니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
