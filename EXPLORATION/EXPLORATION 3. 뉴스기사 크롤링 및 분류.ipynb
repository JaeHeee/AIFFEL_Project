{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORATION 3. 뉴스기사 크롤링 및 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>파주시청. 사진제공=파주시 파주시청. 사진제공=파주시\\n\\n[파주=파이낸셜뉴스 강근...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>동영상 뉴스\\n\\n이천 물류창고 화재 발화지점으로 지목된 지하 2층에서 산소절단기의...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>황범순 의정부시 부시장 을지대학교 의정부캠퍼스 및 부속병원 공사현장 안전점검. 사진...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>귀갓길 여성을 쫓아가 성범죄를 시도한 20대 남성이 구속됐습니다.서울 강남경찰서는 ...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(서울=연합뉴스) 대한약사회가 6일부터 코로나바이러스 감염증 대응 체계를 '사회적 ...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news code\n",
       "0  파주시청. 사진제공=파주시 파주시청. 사진제공=파주시\\n\\n[파주=파이낸셜뉴스 강근...   사회\n",
       "1  동영상 뉴스\\n\\n이천 물류창고 화재 발화지점으로 지목된 지하 2층에서 산소절단기의...   사회\n",
       "2  황범순 의정부시 부시장 을지대학교 의정부캠퍼스 및 부속병원 공사현장 안전점검. 사진...   사회\n",
       "3  귀갓길 여성을 쫓아가 성범죄를 시도한 20대 남성이 구속됐습니다.서울 강남경찰서는 ...   사회\n",
       "4  (서울=연합뉴스) 대한약사회가 6일부터 코로나바이러스 감염증 대응 체계를 '사회적 ...   사회"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = os.getenv(\"HOME\") + \"/aiffel/news_crawler/news_data.csv\"\n",
    "df = pd.read_table(csv_path, sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       파주시청 사진제공파주시 파주시청 사진제공파주시파주파이낸셜뉴스 강근주 기자 파주시는 ...\n",
       "1       동영상 뉴스이천 물류창고 화재 발화지점으로 지목된 지하 층에서 산소절단기의 산소 공...\n",
       "2       황범순 의정부시 부시장 을지대학교 의정부캠퍼스 및 부속병원 공사현장 안전점검 사진제...\n",
       "3       귀갓길 여성을 쫓아가 성범죄를 시도한 대 남성이 구속됐습니다서울 강남경찰서는 강간상...\n",
       "4       서울연합뉴스 대한약사회가 일부터 코로나바이러스 감염증 대응 체계를 사회적 거리두기에...\n",
       "                              ...                        \n",
       "5119    신종 코로나바이러스 감염증코로나 사태 이후 가정의 달 월에도 언택트비대면 신풍속도가...\n",
       "5120    는 소비자로부터 월 이용료 만만원을 받고 초고속 인터넷을 제공한다 그런 브로드밴드가...\n",
       "5121    머리를 긁고 있는 오랑우탄 몸을 긁는 행동을 따라 하는 것은 부정적 감정과 관련이 ...\n",
       "5122    가 오는 일 정식 출시하는 스마트폰 벨벳이 사실상 공짜폰이 될 전망이다 단말기 가격...\n",
       "5123    이미지제공게티이미지뱅크 이미지제공게티이미지뱅크  전자신문  전자신문인터넷 무단전재 ...\n",
       "Name: news, Length: 5124, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규 표현식을 이용해서 한글 외의 문자는 전부 제거합니다.\n",
    "df['news'] = df['news'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "df['news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news    0\n",
      "code    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# null 값이 있는지 확인\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 기사의 개수:  3994\n"
     ]
    }
   ],
   "source": [
    "# 중복된 샘플들을 제거합니다.\n",
    "df.drop_duplicates(subset=['news'], inplace=True)\n",
    "\n",
    "print('뉴스 기사의 개수: ',len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    code  count\n",
      "0  IT/과학    903\n",
      "1     사회   1668\n",
      "2  생활/문화   1423\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('code').size().reset_index(name = 'count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어(stopwords) 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['에','는','은','을','했','에게','있','이','의','하','한','다','과','때문','할','수','무단','따른','및','금지','전재','경향신문','기자','는데','가','등','들','파이낸셜','저작','등','뉴스']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 및 토큰화 과정에서 불용어를 제거하는 함수입니다.\n",
    "def preprocessing(data):\n",
    "    text_data = []\n",
    "\n",
    "    for sentence in data:\n",
    "        temp_data = []\n",
    "        #- 토큰화\n",
    "        temp_data = mecab.morphs(sentence) \n",
    "        #- 불용어 제거\n",
    "        temp_data = [word for word in temp_data if not word in stopwords] \n",
    "        text_data.append(temp_data)\n",
    "\n",
    "    text_data = list(map(' '.join, text_data))\n",
    "\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파주 시청 사진제 공파 주시 파주 시청 사진 제공 파주시 파주 강근주 파 주 시 일 관내 취약 계층 만 가구 대해 정부 긴급 재난 지원금 입금 완료 다파 주 시민 받 긴급 재난 지원금 인 이상 가구 기준 으로 만 원 받 게 되 며 인 가구 만 원 인 가구 만 원 인 가구 만 원 정부 발표 긴급 재난 지원금 파주 시민 지급 금액 다른 이유 국비 지방비 부담 비율 다파 주 시 이미 모든 시민 경기도 파주시 재난 기본 소득 인 당 각 만 원 지급 고 어 시민 국비 지원금 만 지급 며 인 가구 기준 으로 총 지원 금액 파주시 재난 기본소득 만 원 경기도 재난 기본소득 만 원 정부 긴급 재난 지원금 만 원 총 만 원 받 게 된다 취약 계층 아닌 시민 오 월일 부터 소지 고 신용 체크카드 사 홈페이지 에서 긴급 재난 지원금 지원 신청 세대주 가족 지원금 일괄 신청 해야 한다 한편 파 주 시 일 김정기 부시장 단장 으로 긴급 재난 지원금 추진 태 스 크 포스 를 구성 해 긴급 재난 지원금 원활 게 지급 될 도록 지원 한다 권 자 재 배포\n"
     ]
    }
   ],
   "source": [
    "text_data = preprocessing(df['news'])\n",
    "print(text_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터를 분리합니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data, df['code'], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 뉴스 기사의 개수 : 2995\n",
      "테스트용 뉴스 기사의 개수 :  999\n",
      "훈련용 레이블의 개수 :  2995\n",
      "테스트용 레이블의 개수 :  999\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 뉴스 기사의 개수 :', len(X_train))\n",
    "print('테스트용 뉴스 기사의 개수 : ', len(X_test))\n",
    "print('훈련용 레이블의 개수 : ', len(y_train))\n",
    "print('테스트용 레이블의 개수 : ', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- 단어의 수를 카운트하는 사이킷런의 카운트벡터라이저입니다.\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "#- 카운트벡터라이저의 결과로부터 TF-IDF 결과를 얻습니다.\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "#- 나이브 베이즈 분류기를 수행합니다.\n",
    "#- X_train은 TF-IDF 벡터, y_train은 레이블입니다.def tfidf_vectorizer(data):\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectorizer(data):\n",
    "    data_counts = count_vect.transform(data)\n",
    "    data_tfidf = tfidf_transformer.transform(data_counts)\n",
    "    return data_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사회']\n"
     ]
    }
   ],
   "source": [
    "new_sent = preprocessing([\"민주당 일각에서 법사위의 체계·자구 심사 기능을 없애야 한다는 \\\n",
    "                           주장이 나오는 데 대해 “체계·자구 심사가 법안 지연의 수단으로 \\\n",
    "                          쓰이는 것은 바람직하지 않다”면서도 “국회를 통과하는 법안 중 위헌\\\n",
    "                          법률이 1년에 10건 넘게 나온다. 그런데 체계·자구 심사까지 없애면 매우 위험하다”고 반박했다.\"])\n",
    "print(clf.predict(tfidf_vectorizer(new_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['생활/문화']\n"
     ]
    }
   ],
   "source": [
    "new_sent = preprocessing([\"인도 로맨틱 코미디 영화 <까립까립 싱글>(2017)을 봤을 때 나는 두 눈을 의심했다. \\\n",
    "                          저 사람이 남자 주인공이라고? 노안에 가까운 이목구비와 기름때로 뭉친 파마머리와, \\\n",
    "                          대충 툭툭 던지는 말투 등 전혀 로맨틱하지 않은 외모였다. 반감이 일면서 \\\n",
    "                          ‘난 외모지상주의자가 아니다’라고 자부했던 나에 대해 회의가 들었다.\\\n",
    "                           티브이를 꺼버릴까? 다른 걸 볼까? 그런데, 이상하다. 왜 이렇게 매력 있지? 개구리와\\\n",
    "                            같이 툭 불거진 눈망울 안에는 어떤 인도 배우에게서도 느끼지 못한 \\\n",
    "                            부드러움과 선량함, 무엇보다 슬픔이 있었다. 2시간 뒤 영화가 끝나고 나는 완전히 이 배우에게 빠졌다\"])\n",
    "print(clf.predict(tfidf_vectorizer(new_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IT/과학']\n"
     ]
    }
   ],
   "source": [
    "new_sent = preprocessing([\"20분기 연속으로 적자에 시달리는 LG전자가 브랜드 이름부터 성능, 디자인까지 대대적인 변화를 \\\n",
    "                          적용한 LG 벨벳은 등장 전부터 온라인 커뮤니티를 뜨겁게 달궜다. 사용자들은 “디자인이 예쁘다”, \\\n",
    "                          “슬림하다”는 반응을 보이며 LG 벨벳에 대한 기대감을 드러냈다.\"])\n",
    "print(clf.predict(tfidf_vectorizer(new_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.90      0.74      0.81       236\n",
      "          사회       0.79      0.91      0.85       422\n",
      "       생활/문화       0.81      0.76      0.79       341\n",
      "\n",
      "    accuracy                           0.82       999\n",
      "   macro avg       0.83      0.80      0.81       999\n",
      "weighted avg       0.82      0.82      0.82       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(tfidf_vectorizer(X_test))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. 형태소 분석기 변경해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hannanum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "hannanum = Hannanum()\n",
    "\n",
    "# 토큰화 및 불용어 제거\n",
    "def preprocessing_hannanum(data):\n",
    "    text_data = []\n",
    "\n",
    "    for sentence in data:\n",
    "        temp_data = []\n",
    "        #- 토큰화\n",
    "        temp_data = hannanum.morphs(sentence) \n",
    "        #- 불용어 제거\n",
    "        temp_data = [word for word in temp_data if not word in stopwords] \n",
    "        text_data.append(temp_data)\n",
    "\n",
    "        text_data = list(map(' '.join, text_data))\n",
    "\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data_hannanum = preprocessing_hannanum(df['news'])\n",
    "print(text_data_hannanum[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터를 분리합니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data_hannanum, df['code'], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- 단어의 수를 카운트하는 사이킷런의 카운트벡터라이저입니다.\n",
    "count_vect_hannanum = CountVectorizer()\n",
    "X_train_counts_hannanum = count_vect_hannanum.fit_transform(X_train)\n",
    "\n",
    "#- 카운트벡터라이저의 결과로부터 TF-IDF 결과를 얻습니다.\n",
    "tfidf_transformer_hannanum = TfidfTransformer()\n",
    "X_train_tfidf_hannanum = tfidf_transformer_hannanum.fit_transform(X_train_counts_hannanum)\n",
    "\n",
    "#- 나이브 베이즈 분류기를 수행합니다.\n",
    "#- X_train은 TF-IDF 벡터, y_train은 레이블입니다.\n",
    "clf_hannanum = MultinomialNB().fit(X_train_tfidf_hannanum, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectorizer_hannanum(data):\n",
    "    data_counts = count_vect_hannanum.transform(data)\n",
    "    data_tfidf = tfidf_transformer_hannanum.transform(data_counts)\n",
    "    return data_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hannanum\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.90      0.64      0.75       236\n",
      "          사회       0.79      0.91      0.85       422\n",
      "       생활/문화       0.79      0.79      0.79       341\n",
      "\n",
      "    accuracy                           0.81       999\n",
      "   macro avg       0.83      0.78      0.80       999\n",
      "weighted avg       0.82      0.81      0.81       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_hannanum.predict(tfidf_vectorizer_hannanum(X_test))\n",
    "print(\"Hannanum\")\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "\n",
    "# 토큰화 및 불용어 제거\n",
    "def preprocessing_kkma(data):\n",
    "    text_data = []\n",
    "\n",
    "    for sentence in data:\n",
    "        temp_data = []\n",
    "        #- 토큰화\n",
    "        temp_data = kkma.morphs(sentence) \n",
    "        #- 불용어 제거\n",
    "        temp_data = [word for word in temp_data if not word in stopwords] \n",
    "        text_data.append(temp_data)\n",
    "\n",
    "        text_data = list(map(' '.join, text_data))\n",
    "\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data_kkma = preprocessing_kkma(df['news'])\n",
    "print(text_data_kkma[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터를 분리합니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data_kkma, df['code'], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- 단어의 수를 카운트하는 사이킷런의 카운트벡터라이저입니다.\n",
    "count_vect_kkma = CountVectorizer()\n",
    "X_train_counts_kkma = count_vect_kkma.fit_transform(X_train)\n",
    "\n",
    "#- 카운트벡터라이저의 결과로부터 TF-IDF 결과를 얻습니다.\n",
    "tfidf_transformer_kkma = TfidfTransformer()\n",
    "X_train_tfidf_kkma = tfidf_transformer_kkma.fit_transform(X_train_counts_kkma)\n",
    "\n",
    "#- 나이브 베이즈 분류기를 수행합니다.\n",
    "#- X_train은 TF-IDF 벡터, y_train은 레이블입니다.\n",
    "clf_kkma = MultinomialNB().fit(X_train_tfidf_kkma, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectorizer_kkma(data):\n",
    "    data_counts = count_vect_kkma.transform(data)\n",
    "    data_tfidf = tfidf_transformer_kkma.transform(data_counts)\n",
    "    return data_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_kkma.predict(tfidf_vectorizer_kkma(X_test))\n",
    "print(\"Kkma\")\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran()\n",
    "\n",
    "# 토큰화 및 불용어 제거\n",
    "def preprocessing_komoran(data):\n",
    "    text_data = []\n",
    "\n",
    "    for sentence in data:\n",
    "        temp_data = []\n",
    "        #- 토큰화\n",
    "        temp_data = komoran.morphs(sentence) \n",
    "        #- 불용어 제거\n",
    "        temp_data = [word for word in temp_data if not word in stopwords] \n",
    "        text_data.append(temp_data)\n",
    "\n",
    "    text_data = list(map(' '.join, text_data))\n",
    "\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파주 시청 사진 제공 파주시 파주 시청 사진 제공 파주시 파주 파이낸셜뉴스 강 근 주 파주시 일 관내 취약 계층 만 가구 대하 아 정부 긴급 재난 지원금 입금 완료 았 파주시 민이 받 긴급 재난 지원금 인 이상 가구 기준 으로 만원 받 게 되 며 인 가구 만원 인 가구 만원 인 가구 만원 이다 정부 발표 ㄴ 긴급 재난 지원금 파주시 민 지급 ㄴ 금액 다른 이유 국비 지방비 부담 비율 이다 파주시 이미 모든 시민 경기도 파주시 재난 기본소득 인당 각 만원 지급 고 어 시민 국비 지원금 만 지급 며 인 가구 기준 으로 총 지원 금액 파주시 재난 기본소득 만원 경기도 재난 기본소득 만원 정부 긴급 재난 지원금 만원 총 만원 받 게 되 ㄴ 취약 계층 아니 ㄴ 시민 오 월 일 부터 소지 고 신용 체크카드 사 홈페이지 에서 긴급 재난 지원금 지원 신청 ㄹ 세대주 가족 지원금 일괄 신청 아야 한편 파주시 일 김정기 부시장 단장 으로 긴급 재난 지원금 추진 태스크포스를 구성 아 긴급 재난 지원금 원활 게 지급 되 ㄹ 도록 지원 ㄴ다 저작권 자 파이낸셜뉴스 재 배포\n"
     ]
    }
   ],
   "source": [
    "text_data_komoran = preprocessing_komoran(df['news'])\n",
    "print(text_data_komoran[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터를 분리합니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data_komoran, df['code'], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- 단어의 수를 카운트하는 사이킷런의 카운트벡터라이저입니다.\n",
    "count_vect_komoran = CountVectorizer()\n",
    "X_train_counts_komoran = count_vect_komoran.fit_transform(X_train)\n",
    "\n",
    "#- 카운트벡터라이저의 결과로부터 TF-IDF 결과를 얻습니다.\n",
    "tfidf_transformer_komoran = TfidfTransformer()\n",
    "X_train_tfidf_komoran = tfidf_transformer_komoran.fit_transform(X_train_counts_komoran)\n",
    "\n",
    "#- 나이브 베이즈 분류기를 수행합니다.\n",
    "#- X_train은 TF-IDF 벡터, y_train은 레이블입니다.\n",
    "clf_komoran = MultinomialNB().fit(X_train_tfidf_komoran, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectorizer_komoran(data):\n",
    "    data_counts = count_vect_komoran.transform(data)\n",
    "    data_tfidf = tfidf_transformer_komoran.transform(data_counts)\n",
    "    return data_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Komoran\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.90      0.74      0.81       236\n",
      "          사회       0.80      0.91      0.85       422\n",
      "       생활/문화       0.81      0.77      0.79       341\n",
      "\n",
      "    accuracy                           0.82       999\n",
      "   macro avg       0.83      0.81      0.82       999\n",
      "weighted avg       0.83      0.82      0.82       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_komoran.predict(tfidf_vectorizer_komoran(X_test))\n",
    "print(\"Komoran\")\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "# 토큰화 및 불용어 제거\n",
    "def preprocessing_okt(data):\n",
    "    text_data = []\n",
    "\n",
    "    for sentence in data:\n",
    "        temp_data = []\n",
    "        #- 토큰화\n",
    "        temp_data = okt.morphs(sentence) \n",
    "        #- 불용어 제거\n",
    "        temp_data = [word for word in temp_data if not word in stopwords] \n",
    "        text_data.append(temp_data)\n",
    "\n",
    "    text_data = list(map(' '.join, text_data))\n",
    "\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파주 시청 사진 제공 파주시 파주 시청 사진 제공 파주시 파주 파이낸셜뉴스 강 근 주 파주시 일 관내 취약 계층 만 가구 대해 정부 긴급 재난 지 원금 입금 완료 했다 파주시민 받는 긴급 재난 지원 금은 인 이상 가구 기준 으로 만원 받게 되며 인 가구 만원 인 가구 만원 인 가구 만원 이다 정부 발표 긴급 재난 지 원금 파주시민 지급 금액 다른 이유 국비 지 방비 부담 비율 이다 파주시 이미 모든 시민 경기도 파주시 재난 기본소득 인 당 각 만원 지급 하고 있어 시민 국비 지 원금 만 지급 하며 인 가구 기준 으로 총 지원 금액 파주시 재난 기본소득 만원 경기도 재난 기본소득 만원 정부 긴급 재난 지 원금 만원 총 만원 받게 된다 취약 계층 아닌 시민 오는 월일 부터 소지 하고 있는 신용 체크카드 사 홈페이지 에서 긴급 재난 지 원금 지원 신청 있다 세대주 가족 지 원금 일괄 신청 해야 한다 한편 파주시 일 김정기 부시장 단장 으로 하는 긴급 재난 지 원금 추진 태스크포스 를 구성 해 긴급 재난 지 원금 원활하게 지급 될 있도록 지원 저작권 자 파이낸셜뉴스 전 재재 배포\n"
     ]
    }
   ],
   "source": [
    "text_data_okt = preprocessing_okt(df['news'])\n",
    "print(text_data_okt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터를 분리합니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data_okt, df['code'], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- 단어의 수를 카운트하는 사이킷런의 카운트벡터라이저입니다.\n",
    "count_vect_okt = CountVectorizer()\n",
    "X_train_counts_okt = count_vect_okt.fit_transform(X_train)\n",
    "\n",
    "#- 카운트벡터라이저의 결과로부터 TF-IDF 결과를 얻습니다.\n",
    "tfidf_transformer_okt = TfidfTransformer()\n",
    "X_train_tfidf_okt = tfidf_transformer_okt.fit_transform(X_train_counts_okt)\n",
    "\n",
    "#- 나이브 베이즈 분류기를 수행합니다.\n",
    "#- X_train은 TF-IDF 벡터, y_train은 레이블입니다.\n",
    "clf_okt = MultinomialNB().fit(X_train_tfidf_okt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectorizer_okt(data):\n",
    "    data_counts = count_vect_okt.transform(data)\n",
    "    data_tfidf = tfidf_transformer_okt.transform(data_counts)\n",
    "    return data_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okt\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.91      0.70      0.79       236\n",
      "          사회       0.78      0.93      0.85       422\n",
      "       생활/문화       0.83      0.76      0.79       341\n",
      "\n",
      "    accuracy                           0.82       999\n",
      "   macro avg       0.84      0.80      0.81       999\n",
      "weighted avg       0.83      0.82      0.82       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_okt.predict(tfidf_vectorizer_okt(X_test))\n",
    "print(\"Okt\")\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. 불용어 추가해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['에', '는', '은', '을', '했', '에게', '있', '이', '의', '하', '한', '다', '과', '때문', '할', '수', '무단', '따른', '및', '금지', '전재', '경향신문', '기자', '는데', '가', '등', '들', '파이낸셜', '저작', '등', '뉴스']\n"
     ]
    }
   ],
   "source": [
    "new_stopwords = stopwords[:]\n",
    "print(new_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2299\n"
     ]
    }
   ],
   "source": [
    "file_path1 = os.getenv(\"HOME\") + \"/aiffel/news_crawler/EOMI2.TXT\"\n",
    "\n",
    "with open(file_path1) as file_object:\n",
    "    contents = file_object.read()\n",
    "\n",
    "for c in contents:\n",
    "    if c != '\\n' and c != '\\x1a':\n",
    "        new_stopwords.append(c)\n",
    "\n",
    "print(len(new_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3693\n"
     ]
    }
   ],
   "source": [
    "file_path2 = os.getenv(\"HOME\") + \"/aiffel/news_crawler/JOSA2.TXT\"\n",
    "\n",
    "with open(file_path2) as file_object:\n",
    "    contents = file_object.read()\n",
    "\n",
    "for c in contents:\n",
    "    if c != '\\n' and c != '\\x1a':\n",
    "        new_stopwords.append(c)\n",
    "\n",
    "print(len(new_stopwords))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from konlpy.tag import Okt\n",
    "# okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 및 불용어 제거\n",
    "def preprocessing_new(data):\n",
    "    text_data = []\n",
    "\n",
    "    for sentence in data:\n",
    "        temp_data = []\n",
    "        #- 토큰화\n",
    "        temp_data = mecab.morphs(sentence) \n",
    "        #- 불용어 제거\n",
    "        temp_data = [word for word in temp_data if not word in new_stopwords] \n",
    "        text_data.append(temp_data)\n",
    "\n",
    "    text_data = list(map(' '.join, text_data))\n",
    "\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파주 시청 사진제 공파 주시 파주 시청 사진 제공 파주시 파주 강근주 파 주 관내 취약 계층 가구 대해 정부 긴급 재난 지원금 입금 완료 다파 주 시민 받 긴급 재난 지원금 이상 가구 기준 으로 원 받 가구 원 가구 원 가구 원 정부 발표 긴급 재난 지원금 파주 시민 지급 금액 다른 이유 국비 지방비 부담 비율 다파 주 이미 모든 시민 경기도 파주시 재난 기본 소득 당 각 원 지급 시민 국비 지원금 지급 가구 기준 으로 총 지원 금액 파주시 재난 기본소득 원 경기도 재난 기본소득 원 정부 긴급 재난 지원금 원 총 원 받 된다 취약 계층 아닌 시민 월일 부터 소지 신용 체크카드 홈페이지 에서 긴급 재난 지원금 지원 신청 세대주 가족 지원금 일괄 신청 해야 한다 한편 파 주 김정기 부시장 단장 으로 긴급 재난 지원금 추진 태 스 크 포스 구성 해 긴급 재난 지원금 원활 지급 될 도록 지원 한다 권 재 배포\n"
     ]
    }
   ],
   "source": [
    "text_data_new = preprocessing_new(df['news'])\n",
    "print(text_data_new[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터를 분리합니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data_new, df['code'], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- 단어의 수를 카운트하는 사이킷런의 카운트벡터라이저입니다.\n",
    "count_vect_new = CountVectorizer()\n",
    "X_train_counts_new = count_vect_new.fit_transform(X_train)\n",
    "\n",
    "#- 카운트벡터라이저의 결과로부터 TF-IDF 결과를 얻습니다.\n",
    "tfidf_transformer_new = TfidfTransformer()\n",
    "X_train_tfidf_new = tfidf_transformer_new.fit_transform(X_train_counts_new)\n",
    "\n",
    "#- 나이브 베이즈 분류기를 수행합니다.\n",
    "#- X_train은 TF-IDF 벡터, y_train은 레이블입니다.\n",
    "clf_new = MultinomialNB().fit(X_train_tfidf_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectorizer_new(data):\n",
    "    data_counts = count_vect_new.transform(data)\n",
    "    data_tfidf = tfidf_transformer_new.transform(data_counts)\n",
    "    return data_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(new stopwords)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.90      0.74      0.81       236\n",
      "          사회       0.79      0.91      0.85       422\n",
      "       생활/문화       0.81      0.76      0.79       341\n",
      "\n",
      "    accuracy                           0.82       999\n",
      "   macro avg       0.83      0.80      0.81       999\n",
      "weighted avg       0.82      0.82      0.82       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_new.predict(tfidf_vectorizer_new(X_test))\n",
    "print(\"(new stopwords)\")\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. 다른 날짜 데이터 추가해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path1 = os.getenv(\"HOME\") + \"/aiffel/news_crawler/news_data.csv\"\n",
    "csv_path2 = os.getenv(\"HOME\") + \"/aiffel/news_crawler/news_data2.csv\"\n",
    "\n",
    "df1 = pd.read_table(csv_path1, sep=',')\n",
    "df2 = pd.read_table(csv_path2, sep=',')\n",
    "\n",
    "df_concat = pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>파주시청. 사진제공=파주시 파주시청. 사진제공=파주시\\n\\n[파주=파이낸셜뉴스 강근...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>동영상 뉴스\\n\\n이천 물류창고 화재 발화지점으로 지목된 지하 2층에서 산소절단기의...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>황범순 의정부시 부시장 을지대학교 의정부캠퍼스 및 부속병원 공사현장 안전점검. 사진...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>귀갓길 여성을 쫓아가 성범죄를 시도한 20대 남성이 구속됐습니다.서울 강남경찰서는 ...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(서울=연합뉴스) 대한약사회가 6일부터 코로나바이러스 감염증 대응 체계를 '사회적 ...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3698</th>\n",
       "      <td>레고켐바이오사이언스(대표 김용주·사진)가 글로벌 기술수출에 또다시 성공했다. 201...</td>\n",
       "      <td>IT/과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3699</th>\n",
       "      <td>제21대 국회의원선거 기간 중단됐던 네이버 실시간 급상승 검색어 서비스가 15일 오...</td>\n",
       "      <td>IT/과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>아마존 [AFP=연합뉴스 자료사진] 아마존 [AFP=연합뉴스 자료사진]\\n\\n직원들...</td>\n",
       "      <td>IT/과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3701</th>\n",
       "      <td>제21대 국회의원선거가 임박한 가운데, 투표 및 개표 방송을 준비하는 기업들의 움직...</td>\n",
       "      <td>IT/과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3702</th>\n",
       "      <td>롤 점검이 15일 진행될 예정이다.온라인게임 리그오브레전드(이하 롤)은 15일 오전...</td>\n",
       "      <td>IT/과학</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8827 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   news   code\n",
       "0     파주시청. 사진제공=파주시 파주시청. 사진제공=파주시\\n\\n[파주=파이낸셜뉴스 강근...     사회\n",
       "1     동영상 뉴스\\n\\n이천 물류창고 화재 발화지점으로 지목된 지하 2층에서 산소절단기의...     사회\n",
       "2     황범순 의정부시 부시장 을지대학교 의정부캠퍼스 및 부속병원 공사현장 안전점검. 사진...     사회\n",
       "3     귀갓길 여성을 쫓아가 성범죄를 시도한 20대 남성이 구속됐습니다.서울 강남경찰서는 ...     사회\n",
       "4     (서울=연합뉴스) 대한약사회가 6일부터 코로나바이러스 감염증 대응 체계를 '사회적 ...     사회\n",
       "...                                                 ...    ...\n",
       "3698  레고켐바이오사이언스(대표 김용주·사진)가 글로벌 기술수출에 또다시 성공했다. 201...  IT/과학\n",
       "3699  제21대 국회의원선거 기간 중단됐던 네이버 실시간 급상승 검색어 서비스가 15일 오...  IT/과학\n",
       "3700  아마존 [AFP=연합뉴스 자료사진] 아마존 [AFP=연합뉴스 자료사진]\\n\\n직원들...  IT/과학\n",
       "3701  제21대 국회의원선거가 임박한 가운데, 투표 및 개표 방송을 준비하는 기업들의 움직...  IT/과학\n",
       "3702  롤 점검이 15일 진행될 예정이다.온라인게임 리그오브레전드(이하 롤)은 15일 오전...  IT/과학\n",
       "\n",
       "[8827 rows x 2 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       파주시청 사진제공파주시 파주시청 사진제공파주시파주파이낸셜뉴스 강근주 기자 파주시는 ...\n",
       "1       동영상 뉴스이천 물류창고 화재 발화지점으로 지목된 지하 층에서 산소절단기의 산소 공...\n",
       "2       황범순 의정부시 부시장 을지대학교 의정부캠퍼스 및 부속병원 공사현장 안전점검 사진제...\n",
       "3       귀갓길 여성을 쫓아가 성범죄를 시도한 대 남성이 구속됐습니다서울 강남경찰서는 강간상...\n",
       "4       서울연합뉴스 대한약사회가 일부터 코로나바이러스 감염증 대응 체계를 사회적 거리두기에...\n",
       "                              ...                        \n",
       "3698    레고켐바이오사이언스대표 김용주사진가 글로벌 기술수출에 또다시 성공했다 년 중국 포순...\n",
       "3699    제대 국회의원선거 기간 중단됐던 네이버 실시간 급상승 검색어 서비스가 일 오후 시부...\n",
       "3700    아마존 연합뉴스 자료사진 아마존 연합뉴스 자료사진직원들 코로나 확산 방지 조치 충분...\n",
       "3701    제대 국회의원선거가 임박한 가운데 투표 및 개표 방송을 준비하는 기업들의 움직임이 ...\n",
       "3702    롤 점검이 일 진행될 예정이다온라인게임 리그오브레전드이하 롤은 일 오전 시부터 오전...\n",
       "Name: news, Length: 8827, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규 표현식을 이용해서 한글 외의 문자는 전부 제거합니다.\n",
    "df_concat['news'] = df_concat['news'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "df_concat['news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 기사의 개수:  6127\n"
     ]
    }
   ],
   "source": [
    "# 중복된 샘플들을 제거합니다.\n",
    "df_concat.drop_duplicates(subset=['news'], inplace=True)\n",
    "\n",
    "print('뉴스 기사의 개수: ',len(df_concat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    code  count\n",
      "0  IT/과학   1138\n",
      "1     경제    901\n",
      "2     사회   2222\n",
      "3  생활/문화   1866\n"
     ]
    }
   ],
   "source": [
    "print(df_concat.groupby('code').size().reset_index(name = 'count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from konlpy.tag import Okt\n",
    "# okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 및 토큰화 과정에서 불용어를 제거하는 함수입니다.\n",
    "def preprocessing_concat(data):\n",
    "    text_data = []\n",
    "\n",
    "    for sentence in data:\n",
    "        temp_data = []\n",
    "        #- 토큰화\n",
    "        temp_data = mecab.morphs(sentence) \n",
    "        #- 불용어 제거\n",
    "        temp_data = [word for word in temp_data if not word in new_stopwords] \n",
    "        text_data.append(temp_data)\n",
    "\n",
    "    text_data = list(map(' '.join, text_data))\n",
    "\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파주 시청 사진제 공파 주시 파주 시청 사진 제공 파주시 파주 강근주 파 주 관내 취약 계층 가구 대해 정부 긴급 재난 지원금 입금 완료 다파 주 시민 받 긴급 재난 지원금 이상 가구 기준 으로 원 받 가구 원 가구 원 가구 원 정부 발표 긴급 재난 지원금 파주 시민 지급 금액 다른 이유 국비 지방비 부담 비율 다파 주 이미 모든 시민 경기도 파주시 재난 기본 소득 당 각 원 지급 시민 국비 지원금 지급 가구 기준 으로 총 지원 금액 파주시 재난 기본소득 원 경기도 재난 기본소득 원 정부 긴급 재난 지원금 원 총 원 받 된다 취약 계층 아닌 시민 월일 부터 소지 신용 체크카드 홈페이지 에서 긴급 재난 지원금 지원 신청 세대주 가족 지원금 일괄 신청 해야 한다 한편 파 주 김정기 부시장 단장 으로 긴급 재난 지원금 추진 태 스 크 포스 구성 해 긴급 재난 지원금 원활 지급 될 도록 지원 한다 권 재 배포\n"
     ]
    }
   ],
   "source": [
    "text_data_concat = preprocessing_concat(df_concat['news'])\n",
    "print(text_data_concat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코로나 걸렸 친구 아무래도 좀 멀리 될 아요 재발 가능 성 그리고 누가 기침 해도 쟤 코로나다 라고 놀리 거나 코로나 왕따 당하 학생 생길 어요 올해 고등학교 진학 모양 등교 시작 아무래도 전 보단 예민 상태 학교 다닐 다며 같이 이양 아니 등교 개학 시작 약 주일 앞두 학생 사이 에선 코로나 왕따 우려 번지 이날 사회관 계망 서비스 에선 등교 개학 문제점 시물 공유 여기 이동 수업 이나 급식 시간 중 감염 우려 아니 따돌림 항목 포함 돼 선풍기 이용 화장실 무조건 참 아야 함 일부 내용 정확 정보 바탕 으로 작성 된 지만 코로나 왕따 코로나 환자 대한 사회 적 낙인 배제 학교 에서 발생 다는 현실 적 우려 구체 적 으로 천식 감기 학생 기침 시선 쏠릴 개학 명 코 걸려서 전염 왕따 가능 성 담겼 특히 천식 호흡기 기저 질환 앓 학생 누구 보다 걱정 크 다고 전 모양 오랜만 등교 앞두 조금 설렌다 온라인 수업 보다 직접 수업 듣 이해 된다면서 천식 기침 조절 없 기침 친구 시선 좋 않 다고 우려 역시 천식 중 김모양 호흡 곤란 자주 와서 장시간 마스크 쓰 답답 어지러운 잔기침 때 쏠리 시선 불편 다고 사실상 학기 시작 이나 마찬가지 등교 개학 이후 어떻게 친구 사귀 어야 할지 고민거리 모양 코로나 언제 어디 걸리 는지 모르 학교 모여 의심 환자 될까 우려 된다 선생 님 말씀 안 듣 코 옮긴다고 장난치 애 을까 걱정 라고 김서영 박채영 재 배포\n"
     ]
    }
   ],
   "source": [
    "print(text_data_concat[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터를 분리합니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data_concat, df_concat['code'], stratify=df_concat['code'], test_size=0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 뉴스 기사의 개수 : 4901\n",
      "테스트용 뉴스 기사의 개수 :  1226\n",
      "훈련용 레이블의 개수 :  4901\n",
      "테스트용 레이블의 개수 :  1226\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 뉴스 기사의 개수 :', len(X_train))\n",
    "print('테스트용 뉴스 기사의 개수 : ', len(X_test))\n",
    "print('훈련용 레이블의 개수 : ', len(y_train))\n",
    "print('테스트용 레이블의 개수 : ', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- 단어의 수를 카운트하는 사이킷런의 카운트벡터라이저입니다.\n",
    "count_vect_concat = CountVectorizer()\n",
    "X_train_counts_concat = count_vect_concat.fit_transform(X_train)\n",
    "\n",
    "#- 카운트벡터라이저의 결과로부터 TF-IDF 결과를 얻습니다.\n",
    "tfidf_transformer_concat = TfidfTransformer()\n",
    "X_train_tfidf_concat = tfidf_transformer_concat.fit_transform(X_train_counts_concat)\n",
    "\n",
    "#- 나이브 베이즈 분류기를 수행합니다.\n",
    "#- X_train은 TF-IDF 벡터, y_train은 레이블입니다.def tfidf_vectorizer(data):\n",
    "clf_concat = MultinomialNB().fit(X_train_tfidf_concat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectorizer_concat(data):\n",
    "    data_counts = count_vect_concat.transform(data)\n",
    "    data_tfidf = tfidf_transformer_concat.transform(data_counts)\n",
    "    return data_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.84      0.69      0.76       228\n",
      "          경제       0.91      0.49      0.64       180\n",
      "          사회       0.73      0.90      0.81       445\n",
      "       생활/문화       0.73      0.76      0.74       373\n",
      "\n",
      "    accuracy                           0.76      1226\n",
      "   macro avg       0.80      0.71      0.74      1226\n",
      "weighted avg       0.77      0.76      0.75      1226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_concat.predict(tfidf_vectorizer_concat(X_test))\n",
    "print(\"add data\")\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
