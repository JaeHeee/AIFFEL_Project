{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORATION 19. 흐린 사진을 선명하게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 데이터를 불러옵니다.\n",
    "train, valid = tfds.load(\n",
    "    \"div2k/bicubic_x4\", \n",
    "    split=[\"train\",\"validation\"],\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "# 시각화를 위해 한 개의 데이터만 선택합니다.\n",
    "for i, (lr, hr) in enumerate(valid):\n",
    "    if i == 6: break\n",
    "    \n",
    "# 저해상도 이미지를 고해상도 이미지 크기로 bicubic interpolation 합니다.  \n",
    "hr, lr = np.array(hr), np.array(lr)\n",
    "bicubic_hr = cv2.resize(\n",
    "    lr, \n",
    "    dsize=(hr.shape[1], hr.shape[0]), # 고해상도 이미지 크기로 설정\n",
    "    interpolation=cv2.INTER_CUBIC # bicubic 설정\n",
    ")\n",
    "\n",
    "# 저해상도 및 고해상도 이미지를 시각화 합니다.\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1); plt.imshow(bicubic_hr)\n",
    "plt.subplot(1,2,2); plt.imshow(hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지의 특정 부분을 잘라내는 함수를 정의합니다.\n",
    "def crop(image, left_top, x=200, y=200):\n",
    "    return image[left_top[0]:(left_top[0]+x), left_top[1]:(left_top[1]+y), :]\n",
    "\n",
    "# interpolation된 이미지와 고해상도 이미지의 동일한 부분을 각각 잘라냅니다.\n",
    "left_top = (400, 500)\n",
    "crop_bicubic_hr = crop(bicubic_hr, left_top)\n",
    "crop_hr = crop(hr, left_top)\n",
    "\n",
    "# 잘라낸 부분을 시각화 합니다.\n",
    "plt.figure(figsize=(15,25))\n",
    "plt.subplot(1,2,1); plt.imshow(crop_bicubic_hr); plt.title(\"Bicubic\", fontsize=30)\n",
    "plt.subplot(1,2,2); plt.imshow(crop_hr); plt.title(\"HR\", fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocessing(lr, hr):\n",
    "    # 이미지의 크기가 크므로 (96,96,3) 크기로 임의 영역을 잘라내어 사용합니다.\n",
    "    hr = tf.image.random_crop(hr, size=[96, 96, 3])\n",
    "    hr = tf.cast(hr, tf.float32) / 255.\n",
    "    \n",
    "    # 잘라낸 고해상도 이미지의 가로, 세로 픽셀 수를 1/4배로 줄였다가\n",
    "    # interpolation을 이용해 다시 원래 크기로 되돌립니다.\n",
    "    # 이렇게 만든 저해상도 이미지를 입력으로 사용합니다.\n",
    "    lr = tf.image.resize(hr, [96//4, 96//4], \"bicubic\")\n",
    "    lr = tf.image.resize(lr, [96, 96], \"bicubic\")\n",
    "    return lr, hr\n",
    "\n",
    "train = train.map(preprocessing).shuffle(buffer_size=10).batch(16)\n",
    "valid = valid.map(preprocessing).batch(16)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 3개의 convolutional layer를 갖는 Sequential 모델을 구성합니다.\n",
    "srcnn = Sequential()\n",
    "# 9x9 크기의 필터를 128개 사용합니다.\n",
    "srcnn.add(layers.Conv2D(128, 9, padding=\"same\", input_shape=(None, None, 3)))\n",
    "srcnn.add(layers.ReLU())\n",
    "# 5x5 크기의 필터를 64개 사용합니다.\n",
    "srcnn.add(layers.Conv2D(64, 5, padding=\"same\"))\n",
    "srcnn.add(layers.ReLU())\n",
    "# 5x5 크기의 필터를 64개 사용합니다.\n",
    "srcnn.add(layers.Conv2D(3, 5, padding=\"same\"))\n",
    "\n",
    "srcnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcnn.compile(\n",
    "    optimizer=\"adam\", \n",
    "    loss=\"mse\"\n",
    ")\n",
    "\n",
    "srcnn.fit(train, validation_data=valid, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_file = os.getenv('HOME')+'/aiffel/super_resolution/srcnn.h5'\n",
    "srcnn = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_srcnn(image):\n",
    "    sr = srcnn.predict(image[np.newaxis, ...]/255.)\n",
    "    sr[sr > 1] = 1\n",
    "    sr[sr < 0] = 0\n",
    "    sr *= 255.\n",
    "    return np.array(sr[0].astype(np.uint8))\n",
    "\n",
    "srcnn_hr = apply_srcnn(bicubic_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자세히 시각화 하기 위해 3개 영역을 잘라냅니다.\n",
    "# 아래는 잘라낸 부분의 좌상단 좌표 3개 입니다.\n",
    "left_tops = [(400,500), (300,1200), (0,1000)]\n",
    "\n",
    "images = []\n",
    "for left_top in left_tops:\n",
    "    img1 = crop(bicubic_hr, left_top, 200, 200)\n",
    "    img2 = crop(srcnn_hr , left_top, 200, 200)\n",
    "    img3 = crop(hr, left_top, 200, 200)\n",
    "    images.extend([img1, img2, img3])\n",
    "\n",
    "labels = [\"Bicubic\", \"SRCNN\", \"HR\"] * 3\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1) \n",
    "    plt.imshow(images[i])\n",
    "    plt.title(labels[i], fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = tfds.load(\n",
    "    \"div2k/bicubic_x4\", \n",
    "    split=[\"train\",\"validation\"],\n",
    "    as_supervised=True\n",
    ")\n",
    "def preprocessing(lr, hr):\n",
    "    hr = tf.cast(hr, tf.float32) /255.\n",
    "        \n",
    "    # 이미지의 크기가 크므로 (96,96,3) 크기로 임의 영역을 잘라내어 사용합니다.\n",
    "    hr_patch = tf.image.random_crop(hr, size=[96,96,3])\n",
    "        \n",
    "    # 잘라낸 고해상도 이미지의 가로, 세로 픽셀 수를 1/4배로 줄입니다\n",
    "    # 이렇게 만든 저해상도 이미지를 SRGAN의 입력으로 사용합니다.\n",
    "    lr_patch = tf.image.resize(hr_patch, [96//4, 96//4], \"bicubic\")\n",
    "    return lr_patch, hr_patch\n",
    "\n",
    "train = train.map(preprocessing).shuffle(buffer_size=10).repeat().batch(8)\n",
    "valid = valid.map(preprocessing).repeat().batch(8)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 그림의 파란색 블록을 정의합니다.\n",
    "def gene_base_block(x):\n",
    "    out = layers.Conv2D(64, 3, 1, \"same\")(x)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.PReLU(shared_axes=[1,2])(out)\n",
    "    out = layers.Conv2D(64, 3, 1, \"same\")(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    return layers.Add()([x, out])\n",
    "\n",
    "# 그림의 뒤쪽 연두색 블록을 정의합니다.\n",
    "def upsample_block(x):\n",
    "    out = layers.Conv2D(256, 3, 1, \"same\")(x)\n",
    "    # 그림의 PixelShuffler 라고 쓰여진 부분을 아래와 같이 구현합니다.\n",
    "    out = layers.Lambda(lambda x: tf.nn.depth_to_space(x, 2))(out)\n",
    "    return layers.PReLU(shared_axes=[1,2])(out)\n",
    "    \n",
    "# 전체 Generator를 정의합니다.\n",
    "def get_generator(input_shape=(None, None, 3)):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    out = layers.Conv2D(64, 9, 1, \"same\")(inputs)\n",
    "    out = residual = layers.PReLU(shared_axes=[1,2])(out)\n",
    "    \n",
    "    for _ in range(5):\n",
    "        out = gene_base_block(out)\n",
    "    \n",
    "    out = layers.Conv2D(64, 3, 1, \"same\")(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.Add()([residual, out])\n",
    "    \n",
    "    for _ in range(2):\n",
    "        out = upsample_block(out)\n",
    "        \n",
    "    out = layers.Conv2D(3, 9, 1, \"same\", activation=\"tanh\")(out)\n",
    "    return Model(inputs, out)\n",
    "\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그림의 파란색 블록을 정의합니다.\n",
    "def disc_base_block(x, n_filters=128):\n",
    "    out = layers.Conv2D(n_filters, 3, 1, \"same\")(x)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.LeakyReLU()(out)\n",
    "    out = layers.Conv2D(n_filters, 3, 2, \"same\")(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    return layers.LeakyReLU()(out)\n",
    "\n",
    "# 전체 Discriminator 정의합니다.\n",
    "def get_discriminator(input_shape=(None, None, 3)):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    out = layers.Conv2D(64, 3, 1, \"same\")(inputs)\n",
    "    out = layers.LeakyReLU()(out)\n",
    "    out = layers.Conv2D(64, 3, 2, \"same\")(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.LeakyReLU()(out)\n",
    "    \n",
    "    for n_filters in [128, 256, 512]:\n",
    "        out = disc_base_block(out, n_filters)\n",
    "    \n",
    "    out = layers.Dense(1024)(out)\n",
    "    out = layers.LeakyReLU()(out)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(out)\n",
    "    return Model(inputs, out)\n",
    "\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_feature_extractor(input_shape=(None, None, 3)):\n",
    "    vgg = applications.vgg19.VGG19(\n",
    "        include_top=False, \n",
    "        weights=\"imagenet\", \n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    # 아래 vgg.layers[20]은 vgg 내의 마지막 convolutional layer 입니다.\n",
    "    return Model(vgg.input, vgg.layers[20].output)\n",
    "\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "generator = get_generator()\n",
    "discriminator = get_discriminator()\n",
    "vgg = get_feature_extractor()\n",
    "\n",
    "# 사용할 loss function 및 optimizer 를 정의합니다.\n",
    "bce = losses.BinaryCrossentropy(from_logits=False)\n",
    "mse = losses.MeanSquaredError()\n",
    "gene_opt = optimizers.Adam()\n",
    "disc_opt = optimizers.Adam()\n",
    "\n",
    "def get_gene_loss(fake_out):\n",
    "    return bce(tf.ones_like(fake_out), fake_out)\n",
    "\n",
    "def get_disc_loss(real_out, fake_out):\n",
    "    return bce(tf.ones_like(real_out), real_out) + bce(tf.zeros_like(fake_out), fake_out)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_content_loss(hr_real, hr_fake):\n",
    "    hr_real = applications.vgg19.preprocess_input(hr_real)\n",
    "    hr_fake = applications.vgg19.preprocess_input(hr_fake)\n",
    "    \n",
    "    hr_real_feature = vgg(hr_real) / 12.75\n",
    "    hr_fake_feature = vgg(hr_fake) / 12.75\n",
    "    return mse(hr_real_feature, hr_fake_feature)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def step(lr, hr_real):\n",
    "    with tf.GradientTape() as gene_tape, tf.GradientTape() as disc_tape:\n",
    "        hr_fake = generator(lr, training=True)\n",
    "        \n",
    "        real_out = discriminator(hr_real, training=True)\n",
    "        fake_out = discriminator(hr_fake, training=True)\n",
    "        \n",
    "        perceptual_loss = get_content_loss(hr_real, hr_fake) + 1e-3 * get_gene_loss(fake_out)\n",
    "        discriminator_loss = get_disc_loss(real_out, fake_out)\n",
    "        \n",
    "    gene_gradient = gene_tape.gradient(perceptual_loss, generator.trainable_variables)\n",
    "    disc_gradient = disc_tape.gradient(discriminator_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    gene_opt.apply_gradients(zip(gene_gradient, generator.trainable_variables))\n",
    "    disc_opt.apply_gradients(zip(disc_gradient, discriminator.trainable_variables))\n",
    "    return perceptual_loss, discriminator_loss\n",
    "\n",
    "\n",
    "gene_losses = metrics.Mean()\n",
    "disc_losses = metrics.Mean()\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "    for i, (lr, hr) in enumerate(train):\n",
    "        g_loss, d_loss = step(lr, hr)\n",
    "        \n",
    "        gene_losses.update_state(g_loss)\n",
    "        disc_losses.update_state(d_loss)\n",
    "        \n",
    "        # 10회 반복마다 loss를 출력합니다.\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"EPOCH[{epoch}] - STEP[{i+1}] \\nGenerator_loss:{gene_losses.result():.4f} \\nDiscriminator_loss:{disc_losses.result():.4f}\", end=\"\\n\\n\")\n",
    "        \n",
    "        if (i+1) == 200:\n",
    "            break\n",
    "            \n",
    "    gene_losses.reset_states()\n",
    "    disc_losses.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_file = os.getenv('HOME')+'/aiffel/super_resolution/srgan_G.h5'\n",
    "srgan = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_srgan(image):\n",
    "    image = tf.cast(image[np.newaxis, ...], tf.float32)\n",
    "    sr = srgan.predict(image)\n",
    "    sr = tf.clip_by_value(sr, 0, 255)\n",
    "    sr = tf.round(sr)\n",
    "    sr = tf.cast(sr, tf.uint8)\n",
    "    return np.array(sr)[0]\n",
    "\n",
    "train, valid = tfds.load(\n",
    "    \"div2k/bicubic_x4\", \n",
    "    split=[\"train\",\"validation\"],\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "for i, (lr, hr) in enumerate(valid):\n",
    "    if i == 6: break\n",
    "\n",
    "srgan_hr = apply_srgan(lr)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자세히 시각화 하기 위해 3개 영역을 잘라냅니다.\n",
    "# 아래는 잘라낸 부분의 좌상단 좌표 3개 입니다.\n",
    "left_tops = [(400,500), (300,1200), (0,1000)]\n",
    "\n",
    "images = []\n",
    "for left_top in left_tops:\n",
    "    img1 = crop(bicubic_hr, left_top, 200, 200)\n",
    "    img2 = crop(srgan_hr , left_top, 200, 200)\n",
    "    img3 = crop(hr, left_top, 200, 200)\n",
    "    images.extend([img1, img2, img3])\n",
    "\n",
    "labels = [\"Bicubic\", \"SRGAN\", \"HR\"] * 3\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1) \n",
    "    plt.imshow(images[i])\n",
    "    plt.title(labels[i], fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hr_cat = data.chelsea() # skimage에서 제공하는 예제 이미지를 불러옵니다.\n",
    "hr_shape = hr_cat.shape[:2]\n",
    "\n",
    "print(hr_cat.shape) # 이미지의 크기를 출력합니다.\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.imshow(hr_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "print(\"**동일 이미지 비교**\")\n",
    "print(\"PSNR :\", peak_signal_noise_ratio(hr_cat, hr_cat))\n",
    "print(\"SSIM :\", structural_similarity(hr_cat, hr_cat, multichannel=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 이미지를 특정 크기로 줄이고 다시 늘리는 과정을 함수로 정의합니다.\n",
    "def interpolation_xn(image, n):\n",
    "    downsample = cv2.resize(\n",
    "        image,\n",
    "        dsize=(hr_shape[1]//n, hr_shape[0]//n)\n",
    "    )\n",
    "    upsample = cv2.resize(\n",
    "        downsample,\n",
    "        dsize=(hr_shape[1], hr_shape[0]),\n",
    "        interpolation=cv2.INTER_CUBIC\n",
    "    )\n",
    "    return upsample\n",
    "\n",
    "lr2_cat = interpolation_xn(hr_cat, 2) # 1/2로 줄이고 다시 복원\n",
    "lr4_cat = interpolation_xn(hr_cat, 4) # 1/4로 줄이고 다시 복원\n",
    "lr8_cat = interpolation_xn(hr_cat, 8) # 1/8로 줄이고 다시 복원\n",
    "\n",
    "images = [hr_cat, lr2_cat, lr4_cat, lr8_cat]\n",
    "titles = [\"HR\", \"x2\", \"x4\", \"x8\"]\n",
    "\n",
    "# 각 이미지에 대해 PSNR을 계산하고 반올림합니다.\n",
    "psnr = [round(peak_signal_noise_ratio(hr_cat, i), 3) for i in images]\n",
    "# 각 이미지에 대해 SSIM을 계산하고 반올림합니다.\n",
    "ssim = [round(structural_similarity(hr_cat, i, multichannel=True), 3) for i in images]\n",
    "\n",
    "# 이미지 제목에 PSNR과 SSIM을 포함하여 시각화 합니다. \n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(titles[i] + f\" [{psnr[i]}/{ssim[i]}]\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (lr, hr) in enumerate(valid):\n",
    "    if i == 12: break # 12번째 이미지를 불러옵니다.\n",
    "\n",
    "lr_img, hr_img = np.array(lr), np.array(hr)\n",
    "\n",
    "# bicubic interpolation\n",
    "bicubic_img = cv2.resize(\n",
    "    lr_img, \n",
    "    (hr.shape[1], hr.shape[0]), \n",
    "    interpolation=cv2.INTER_CUBIC\n",
    ")\n",
    "\n",
    "# 전체 이미지를 시각화합니다.\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.subplot(311); plt.imshow(hr_img)\n",
    "\n",
    "# SRCNN을 이용해 고해상도로 변환합니다.\n",
    "srcnn_img = apply_srcnn(bicubic_img)\n",
    "\n",
    "# SRGAN을 이용해 고해상도로 변환합니다.\n",
    "srgan_img = apply_srgan(lr_img)\n",
    "\n",
    "images = [bicubic_img, srcnn_img, srgan_img, hr_img]\n",
    "titles = [\"Bicubic\", \"SRCNN\", \"SRGAN\", \"HR\"]\n",
    "\n",
    "left_top = (700, 1090) # 잘라낼 부분의 왼쪽 상단 좌표를 지정합니다.\n",
    "\n",
    "# bicubic, SRCNN, SRGAN 을 적용한 이미지와 원래의 고해상도 이미지를 시각화합니다.\n",
    "plt.figure(figsize=(20,20))\n",
    "for i, pind in enumerate([321, 322, 323, 324]):\n",
    "    plt.subplot(pind)\n",
    "    plt.imshow(crop(images[i], left_top, 200, 350))\n",
    "    plt.title(titles[i], fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (lr, hr) in enumerate(valid):\n",
    "    if i == 15: break\n",
    "\n",
    "lr_img, hr_img = np.array(lr), np.array(hr)\n",
    "bicubic_img = cv2.resize(\n",
    "    lr_img, \n",
    "    (hr.shape[1], hr.shape[0]), \n",
    "    interpolation=cv2.INTER_CUBIC\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.subplot(311); plt.imshow(hr_img)\n",
    "\n",
    "srcnn_img = apply_srcnn(bicubic_img)\n",
    "srgan_img = apply_srgan(lr_img)\n",
    "\n",
    "images = [bicubic_img, srcnn_img, srgan_img, hr_img]\n",
    "titles = [\"Bicubic\", \"SRCNN\", \"SRGAN\", \"HR\"]\n",
    "\n",
    "left_top = (600, 1500)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for i, pind in enumerate([321, 322, 323, 324]):\n",
    "    plt.subplot(pind)\n",
    "    plt.imshow(crop(images[i], left_top, 200, 350))\n",
    "    plt.title(titles[i], fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (lr, hr) in enumerate(valid):\n",
    "    if i == 8: break\n",
    "\n",
    "lr_img, hr_img = np.array(lr), np.array(hr)\n",
    "bicubic_img = cv2.resize(\n",
    "    lr_img, \n",
    "    (hr.shape[1], hr.shape[0]), \n",
    "    interpolation=cv2.INTER_CUBIC\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.subplot(311); plt.imshow(hr_img)\n",
    "\n",
    "srcnn_img = apply_srcnn(bicubic_img)\n",
    "srgan_img = apply_srgan(lr_img)\n",
    "\n",
    "images = [bicubic_img, srcnn_img, srgan_img, hr_img]\n",
    "titles = [\"Bicubic\", \"SRCNN\", \"SRGAN\", \"HR\"]\n",
    "\n",
    "left_top = (900, 1500)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for i, pind in enumerate([321, 322, 323, 324]):\n",
    "    plt.subplot(pind)\n",
    "    plt.imshow(crop(images[i], left_top, 200, 350))\n",
    "    plt.title(titles[i], fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (lr, hr) in enumerate(valid):\n",
    "    if i == 24: break\n",
    "\n",
    "lr_img, hr_img = np.array(lr), np.array(hr)\n",
    "bicubic_img = cv2.resize(\n",
    "    lr_img, \n",
    "    (hr.shape[1], hr.shape[0]), \n",
    "    interpolation=cv2.INTER_CUBIC\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.subplot(311); plt.imshow(hr_img)\n",
    "\n",
    "srcnn_img = apply_srcnn(bicubic_img)\n",
    "srgan_img = apply_srgan(lr_img)\n",
    "\n",
    "images = [bicubic_img, srcnn_img, srgan_img, hr_img]\n",
    "titles = [\"Bicubic\", \"SRCNN\", \"SRGAN\", \"HR\"]\n",
    "\n",
    "left_top = (700, 1300)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for i, pind in enumerate([321, 322, 323, 324]):\n",
    "    plt.subplot(pind)\n",
    "    plt.imshow(crop(images[i], left_top, 200, 350))\n",
    "    plt.title(titles[i], fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_top = (620, 570)\n",
    "crop_images = [crop(i, left_top, 150, 250) for i in images]\n",
    "\n",
    "psnr = [round(peak_signal_noise_ratio(crop_images[-1], i), 3) for i in crop_images]\n",
    "ssim = [round(structural_similarity(crop_images[-1], i, multichannel=True), 3) for i in crop_images]\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(crop_images[i])\n",
    "    plt.title(titles[i] + f\" [{psnr[i]}/{ssim[i]}]\", fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (lr, hr) in enumerate(valid):\n",
    "    # 불러올 이미지의 인덱스를 지정합니다.\n",
    "    # 위에서 시각화 했던 8, 12, 15, 24 번을 제외한 다른 숫자를 넣어봅시다 \n",
    "    if i == 2020 : ##TODO##\n",
    "        break          \n",
    "\n",
    "lr_img, hr_img = np.array(lr), np.array(hr)\n",
    "bicubic_img = cv2.resize(\n",
    "    lr_img, \n",
    "    (hr.shape[1], hr.shape[0]), \n",
    "    interpolation=cv2.INTER_CUBIC\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.subplot(311); plt.imshow(hr_img)\n",
    "\n",
    "srcnn_img = apply_srcnn(bicubic_img)\n",
    "srgan_img = apply_srgan(lr_img)\n",
    "\n",
    "images = [bicubic_img, srcnn_img, srgan_img, hr_img]\n",
    "titles = [\"Bicubic\", \"SRCNN\", \"SRGAN\", \"HR\"]\n",
    "\n",
    "# 잘라낼 부분의 왼쪽 상단 좌표를 지정합니다.\n",
    "left_top = (700, 1000) ##TODO## \n",
    "\n",
    "plt.figure(figsize=(20,20)) # 이미지 크기를 조절할 수 있습니다.\n",
    "for i, pind in enumerate([321, 322, 323, 324]):\n",
    "    plt.subplot(pind)\n",
    "\n",
    "    # crop 함수 내의 세번째 네번째 인자를 수정해 이미지 크기를 조절합니다.\n",
    "    plt.imshow(crop(images[i], left_top, 200, 350))\n",
    "    plt.title(titles[i], fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import data\n",
    "import imageio\n",
    "from IPython.display import Image as show_gif\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds \n",
    "from tensorflow.keras import layers, Sequential, Input, Model, losses, metrics, optimizers\n",
    "from tensorflow.python.keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <PrefetchDataset shapes: {hr: (None, None, 3), lr: (None, None, 3)}, types: {hr: tf.uint8, lr: tf.uint8}>,\n",
       " 'validation': <PrefetchDataset shapes: {hr: (None, None, 3), lr: (None, None, 3)}, types: {hr: tf.uint8, lr: tf.uint8}>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.load(\"div2k/bicubic_x4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 직접 고른 이미지로 SRGAN 실험하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRGAN을 이용해 고해상도 gif 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load gif "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame 수 : 8\n",
      "frame 크기 : (255, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "gif = cv2.VideoCapture(\"image/city_night_lr.gif\")\n",
    "\n",
    "isTrue = True\n",
    "frames = []\n",
    "while isTrue:\n",
    "    isTrue, frame = gif.read()\n",
    "    if isTrue:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "\n",
    "print(\"frame 수 :\", len(frames))\n",
    "print(\"frame 크기 :\", (frames[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gif file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimsave(\"image/city_night_hr.gif\", frames_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저해상도\n",
    "show_gif(\"image/city_night_lr.gif\", width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고해상도\n",
    "show_gif(\"image/city_night_hr.gif\", width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
